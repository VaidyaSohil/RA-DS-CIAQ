{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "vietnamese-mediterranean",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# # load your data in dataframe df here\n",
    "# d = {'A':[0.161729, 0.862661, 0.814303, 1.898132, 2.124829], 'B':[0.814335, 0.517964, 0.337391, 1.530963, 0.289176], 'C':[1.2 ,2.3, 5.2, 2.1, 5.2]}\n",
    "# df = pd.DataFrame(data=d)\n",
    "# df.head()\n",
    "# #        A         B      C\n",
    "# # 0.161729  0.814335    foo\n",
    "# # 0.862661  0.517964    foo\n",
    "# # 0.814303  0.337391    foo\n",
    "# # 1.898132  1.530963    bar\n",
    "# # 2.124829  0.289176    bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "graduate-colors",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('X:\\RA_AirQuality\\combined_final_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "acquired-counter",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[pd.isnull(df['PM2.5'])==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "descending-thanksgiving",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.fillna(df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "isolated-diversity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "homeless-census",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7273, 14)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "wrong-glenn",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NO</th>\n",
       "      <th>NO2</th>\n",
       "      <th>PM10</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>HUM</th>\n",
       "      <th>DIR</th>\n",
       "      <th>SPD</th>\n",
       "      <th>PRES</th>\n",
       "      <th>Month</th>\n",
       "      <th>Hour</th>\n",
       "      <th>TF_CNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>-13.26</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.66</td>\n",
       "      <td>7.00</td>\n",
       "      <td>8.62</td>\n",
       "      <td>6.30</td>\n",
       "      <td>80.04</td>\n",
       "      <td>189.90</td>\n",
       "      <td>2.65</td>\n",
       "      <td>625.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2042.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01 01:00:00</td>\n",
       "      <td>-14.22</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.66</td>\n",
       "      <td>6.00</td>\n",
       "      <td>8.71</td>\n",
       "      <td>4.41</td>\n",
       "      <td>75.21</td>\n",
       "      <td>282.43</td>\n",
       "      <td>2.70</td>\n",
       "      <td>625.24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1949.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01 02:00:00</td>\n",
       "      <td>-14.30</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.63</td>\n",
       "      <td>7.31</td>\n",
       "      <td>6.82</td>\n",
       "      <td>5.24</td>\n",
       "      <td>79.09</td>\n",
       "      <td>310.47</td>\n",
       "      <td>2.26</td>\n",
       "      <td>630.04</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1527.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01 03:00:00</td>\n",
       "      <td>-14.44</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.56</td>\n",
       "      <td>6.42</td>\n",
       "      <td>9.10</td>\n",
       "      <td>6.56</td>\n",
       "      <td>79.54</td>\n",
       "      <td>295.01</td>\n",
       "      <td>2.18</td>\n",
       "      <td>630.40</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1403.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01 04:00:00</td>\n",
       "      <td>-14.82</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.72</td>\n",
       "      <td>8.13</td>\n",
       "      <td>5.94</td>\n",
       "      <td>4.70</td>\n",
       "      <td>79.86</td>\n",
       "      <td>298.92</td>\n",
       "      <td>1.55</td>\n",
       "      <td>630.40</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1793.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              DateTime   TEMP    CO    NO   NO2  PM10  PM2.5    HUM     DIR  \\\n",
       "0  2019-01-01 00:00:00 -13.26  0.28  1.66  7.00  8.62   6.30  80.04  189.90   \n",
       "1  2019-01-01 01:00:00 -14.22  0.27  0.66  6.00  8.71   4.41  75.21  282.43   \n",
       "2  2019-01-01 02:00:00 -14.30  0.29  0.63  7.31  6.82   5.24  79.09  310.47   \n",
       "3  2019-01-01 03:00:00 -14.44  0.29  0.56  6.42  9.10   6.56  79.54  295.01   \n",
       "4  2019-01-01 04:00:00 -14.82  0.29  0.72  8.13  5.94   4.70  79.86  298.92   \n",
       "\n",
       "    SPD    PRES  Month  Hour  TF_CNT  \n",
       "0  2.65  625.00      1     0  2042.0  \n",
       "1  2.70  625.24      1     1  1949.0  \n",
       "2  2.26  630.04      1     2  1527.0  \n",
       "3  2.18  630.40      1     3  1403.0  \n",
       "4  1.55  630.40      1     4  1793.0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "deluxe-continuity",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PM2.5_Round_Up']=df['PM2.5'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "digital-australian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (pm2.5 > 6) = 1\n",
    "# (pm2.5 <= 6 and pm2.5 >= 3) = 0\n",
    "# (pm2.5 < 3) = -1\n",
    "df['PM2.5_cat']=df['PM2.5'].apply(lambda x: 1 if x>6 else 0 if (x<=6 and x>=3) else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fiscal-journey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    2735\n",
       " 0    2400\n",
       " 1    2138\n",
       "Name: PM2.5_cat, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['PM2.5_cat'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "equivalent-failing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment for Approach 1 (Gaussian + Categorical)\n",
    "# Bin continuous vairbales into 20% quantiles\n",
    "df['TF_CNT_qt'] = pd.qcut(df['TF_CNT'], 5, labels=['bottom 20', 'lower 20', 'middle 20', 'upper 20', 'top 20'])\n",
    "df['SPD_qt'] = pd.qcut(df['SPD'], 5, labels=['bottom 20', 'lower 20', 'middle 20', 'upper 20', 'top 20'])\n",
    "df['DIR_qt'] = pd.qcut(df['DIR'], 5, labels=['bottom 20', 'lower 20', 'middle 20', 'upper 20', 'top 20'])\n",
    "df['NO2_qt'] = pd.qcut(df['NO2'], 5, labels=['bottom 20', 'lower 20', 'middle 20', 'upper 20', 'top 20'])\n",
    "df['TEMP_qt'] = pd.qcut(df['TEMP'], 5, labels=['bottom 20', 'lower 20', 'middle 20', 'upper 20', 'top 20'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-nudist",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternative-configuration",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "impossible-basketball",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that handles sample splitting, model fitting and report printing \n",
    "def mfunc(X, y, typ):\n",
    "    \n",
    "    # Create training and testing samples\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "    # Fit the model\n",
    "    model = typ\n",
    "    clf = model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict class labels on a test data\n",
    "    pred_labels = model.predict(X_test)\n",
    "\n",
    "    # Print model attributes \n",
    "    print('Classes: ', clf.classes_) # class labels known to the classifier\n",
    "    if str(typ)=='GaussianNB()':\n",
    "        print('Class Priors: ',clf.class_prior_) # prior probability of each class.\n",
    "    else: \n",
    "        print('Class Log Priors: ',clf.class_log_prior_) # log prior probability of each class.\n",
    "        \n",
    "    # Use score method to get accuracy of the model\n",
    "    print('--------------------------------------------------------')\n",
    "    score = model.score(X_test, y_test)\n",
    "    print('Accuracy Score: ', score)\n",
    "    print('--------------------------------------------------------')\n",
    "    \n",
    "    # Look at classification report to evaluate the model\n",
    "    print(classification_report(y_test, pred_labels))\n",
    "    \n",
    "    # Probabilities of each class for the test data\n",
    "    print(model.predict_proba(X_test))\n",
    "    \n",
    "    print(\"X_test Shape: \", X_test.shape)\n",
    "    print(X_test)\n",
    "    \n",
    "    print(\"y_test Shape: \", y_test.shape)    \n",
    "    print(y_test)\n",
    "    \n",
    "    # Return relevant data for chart plotting\n",
    "    return X_train, X_test, y_train, y_test, clf, pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "packed-magic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # for data manipulation\n",
    "\n",
    "from sklearn.model_selection import train_test_split # for splitting the data into train and test samples\n",
    "from sklearn.metrics import classification_report # for model evaluation metrics\n",
    "from sklearn.preprocessing import OrdinalEncoder # for encoding categorical features from strings to number arrays\n",
    "\n",
    "import plotly.express as px  # for data visualization\n",
    "import plotly.graph_objects as go # for data visualization\n",
    "\n",
    "# Differnt types of Naive Bayes Classifiers\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "graduate-italic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes:  [-1  0  1]\n",
      "Class Priors:  [0.3774493  0.32605706 0.29649364]\n",
      "--------------------------------------------------------\n",
      "Accuracy Score:  0.50446735395189\n",
      "--------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.56      0.50      0.53       539\n",
      "           0       0.46      0.38      0.41       503\n",
      "           1       0.49      0.67      0.56       413\n",
      "\n",
      "    accuracy                           0.50      1455\n",
      "   macro avg       0.50      0.51      0.50      1455\n",
      "weighted avg       0.51      0.50      0.50      1455\n",
      "\n",
      "[[0.2020553  0.18187301 0.61607169]\n",
      " [0.55112635 0.40657968 0.04229397]\n",
      " [0.34951986 0.42493343 0.2255467 ]\n",
      " ...\n",
      " [0.71462662 0.18575046 0.09962292]\n",
      " [0.49598535 0.43983974 0.0641749 ]\n",
      " [0.1815384  0.22157035 0.59689125]]\n",
      "X_test Shape:  (1455, 4)\n",
      "           TF_CNT   TEMP  Month  Hour\n",
      "2173  7979.000000  -0.20      4    13\n",
      "5780  4934.151461  32.20      8    20\n",
      "4170  6292.000000  16.77      6    18\n",
      "585   7027.000000  -9.90      1     9\n",
      "4198  3854.000000  28.87      6    22\n",
      "...           ...    ...    ...   ...\n",
      "4724  5474.000000  34.67      7    20\n",
      "1553  8215.000000  -0.92      3    17\n",
      "7191  5889.000000  -5.58     10    15\n",
      "5658  4934.151461  24.85      8    18\n",
      "1888  5145.000000   5.70      3    16\n",
      "\n",
      "[1455 rows x 4 columns]\n",
      "y_test Shape:  (1455,)\n",
      "[ 1  0 -1 ... -1  0  1]\n"
     ]
    }
   ],
   "source": [
    "# (pm2.5 > 6) = 1\n",
    "# (pm2.5 <= 6 and pm2.5 >= 3) = 0\n",
    "# (pm2.5 < 3) = -1\n",
    "\n",
    "# Select data for modeling\n",
    "X=df[['TF_CNT','TEMP', 'Month', 'Hour']]\n",
    "y=df['PM2.5_cat'].values\n",
    "\n",
    "# Fit the model and print the result\n",
    "X_train, X_test, y_train, y_test, clf, pred_labels, = mfunc(X, y, GaussianNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "balanced-correction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes:  [-1  0  1]\n",
      "Class Log Priors:  [-0.97431904 -1.12068287 -1.21572951]\n",
      "--------------------------------------------------------\n",
      "Accuracy Score:  0.5223367697594502\n",
      "--------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.58      0.54      0.56       539\n",
      "           0       0.46      0.44      0.45       503\n",
      "           1       0.52      0.60      0.55       413\n",
      "\n",
      "    accuracy                           0.52      1455\n",
      "   macro avg       0.52      0.53      0.52      1455\n",
      "weighted avg       0.52      0.52      0.52      1455\n",
      "\n",
      "Root Mean Square Error: 0.8963461530663467\n",
      "Mean Absolute Error: 0.5862542955326461\n",
      "Mean Squared Error: 0.8034364261168385\n"
     ]
    }
   ],
   "source": [
    "# CATEGORICAL + GAUSSIAN (APPROACH 1)\n",
    "# Select data for modeling\n",
    "X=df[['TF_CNT_qt','TEMP_qt', 'Month', 'Hour']]\n",
    "y=df['PM2.5_cat'].values\n",
    "\n",
    "# Encode categorical variables\n",
    "enc = OrdinalEncoder()\n",
    "X = enc.fit_transform(X)\n",
    "\n",
    "# Fit the model and print the result\n",
    "X_train, X_test, y_train, y_test, clf, pred_labels, = mfunc(X, y, CategoricalNB())\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import math\n",
    "MSE = mean_squared_error(y_test, pred_labels)\n",
    "MAE = mean_absolute_error(y_test, pred_labels)\n",
    "RMSE = math.sqrt(MSE)\n",
    "print(\"Root Mean Square Error:\", RMSE)\n",
    "print(\"Mean Absolute Error:\", MAE)\n",
    "print(\"Mean Squared Error:\", MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overhead-edmonton",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "straight-riverside",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "swedish-reunion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes:  [-1  0  1]\n",
      "Class Priors:  [0.3774493  0.32605706 0.29649364]\n",
      "--------------------------------------------------------\n",
      "Accuracy Score:  0.4323024054982818\n",
      "--------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.40      0.32      0.36       539\n",
      "           0       0.46      0.61      0.52       503\n",
      "           1       0.42      0.37      0.39       413\n",
      "\n",
      "    accuracy                           0.43      1455\n",
      "   macro avg       0.43      0.43      0.42      1455\n",
      "weighted avg       0.43      0.43      0.42      1455\n",
      "\n",
      "[[0.35902912 0.1696102  0.47136068]\n",
      " [0.28300703 0.62488074 0.09211223]\n",
      " [0.31483924 0.55671335 0.12844741]\n",
      " ...\n",
      " [0.28546081 0.04610854 0.66843065]\n",
      " [0.30218944 0.58858212 0.10922844]\n",
      " [0.445108   0.15435508 0.40053692]]\n"
     ]
    }
   ],
   "source": [
    "# CATEGORICAL + GAUSSIAN (APPROACH 2)\n",
    "# ----- Prepare data -----\n",
    "# Select data for modeling\n",
    "X_G=df[['TF_CNT', 'TEMP']] # Gaussian, i.e. continuous\n",
    "X_C=df[['Month', 'Hour']] # Categorical, i.e. discrete\n",
    "y=df['PM2.5_cat'].values\n",
    "\n",
    "# Encode categorical variables\n",
    "enc = OrdinalEncoder()\n",
    "X_C = enc.fit_transform(X_C)\n",
    "\n",
    "# Combine all four variables into one array\n",
    "X=np.c_[X_G, X_C[:,0].ravel(), X_C[:,1].ravel()]\n",
    "\n",
    "# Create training and testing samples\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# ----- Fit the two models -----\n",
    "# Now use the Gaussian model for continuous independent variable and \n",
    "model_G = GaussianNB()\n",
    "clf_G = model_G.fit(X_train[:,0:2], y_train)\n",
    "# Categorical model for discrete independent variable\n",
    "model_C = CategoricalNB()\n",
    "clf_C = model_C.fit(X_train[:,2:4], y_train)\n",
    "\n",
    "\n",
    "# ----- Get probability predictions from each model -----\n",
    "# On training data\n",
    "G_train_probas = model_G.predict_proba(X_train[:,0:2])\n",
    "C_train_probas = model_C.predict_proba(X_train[:,2:4])\n",
    "# And on testing data\n",
    "G_test_probas = model_G.predict_proba(X_test[:,0:2])\n",
    "C_test_probas = model_C.predict_proba(X_test[:,2:4])\n",
    "\n",
    "# Combine probability prediction for class=1 from both models into a 2D array\n",
    "X_new_train = np.c_[(G_train_probas[:,1], C_train_probas[:,1])] # Train\n",
    "X_new_test = np.c_[(G_test_probas[:,1], C_test_probas[:,1])] # Test\n",
    "\n",
    "\n",
    "# ----- Fit Gaussian model on the X_new -----\n",
    "model = GaussianNB()\n",
    "clf = model.fit(X_new_train, y_train)\n",
    "\n",
    "# Predict class labels on a test data\n",
    "pred_labels = model.predict(X_new_test)\n",
    "\n",
    "\n",
    "\n",
    "# ----- Print results -----\n",
    "print('Classes: ', clf.classes_) # class labels known to the classifier\n",
    "print('Class Priors: ',clf.class_prior_) # probability of each class.\n",
    "# Use score method to get accuracy of model\n",
    "print('--------------------------------------------------------')\n",
    "score = model.score(X_new_test, y_test)\n",
    "print('Accuracy Score: ', score)\n",
    "print('--------------------------------------------------------')\n",
    "# Look at classification report to evaluate the model\n",
    "print(classification_report(y_test, pred_labels))\n",
    "\n",
    "\n",
    "\n",
    "# Probabilities of each class for the test data\n",
    "print(model.predict_proba(X_new_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aggregate-roots",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Square Error: 1.0574559368688816\n",
      "Mean Absolute Error: 0.7512027491408935\n",
      "Mean Squared Error: 1.118213058419244\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import math\n",
    "MSE = mean_squared_error(y_test, pred_labels)\n",
    "MAE = mean_absolute_error(y_test, pred_labels)\n",
    "RMSE = math.sqrt(MSE)\n",
    "print(\"Root Mean Square Error:\", RMSE)\n",
    "print(\"Mean Absolute Error:\", MAE)\n",
    "print(\"Mean Squared Error:\", MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "individual-spain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# clf = GaussianNB()\n",
    "# X, y = df[['TF_CNT','TEMP']], df['PM2.5_Round_Up']\n",
    "\n",
    "# # fit the classifier on the training dataset\n",
    "# clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "mediterranean-peoples",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # predict the Pr(C = 'bar' | A, B) with predict_proba() \n",
    "# print(clf.predict_proba([[1,1]])[:,0])   # Pr(C='bar'|A=1.0, B=1.0)\n",
    "# # [ 0.86871233]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "appreciated-lending",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Specify a size of the mesh to be used\n",
    "# mesh_size = 5\n",
    "# margin = 1\n",
    "\n",
    "# # Create a mesh grid on which we will run our model\n",
    "# x_min, x_max = X.iloc[:, 0].fillna(X.mean()).min() - margin, X.iloc[:, 0].fillna(X.mean()).max() + margin\n",
    "# y_min, y_max = X.iloc[:, 1].fillna(X.mean()).min() - margin, X.iloc[:, 1].fillna(X.mean()).max() + margin\n",
    "# xrange = np.arange(x_min, x_max, mesh_size)\n",
    "# yrange = np.arange(y_min, y_max, mesh_size)\n",
    "# xx, yy = np.meshgrid(xrange, yrange)\n",
    "\n",
    "# # Create classifier, run predictions on grid\n",
    "# Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "# Z = Z.reshape(xx.shape)\n",
    "\n",
    "# # Specify traces \n",
    "# trace_specs = [\n",
    "#     #[X_train, y_train, 0, 'Train', 'brown'],\n",
    "#     #[X_train, y_train, 1, 'Train', 'aqua'],\n",
    "#     [X_test, y_test, 0, 'Test', 'red'],\n",
    "#     [X_test, y_test, 1, 'Test', 'blue'],\n",
    "#     [X_test, y_test, -1, 'Test', 'aqua']\n",
    "# ]\n",
    "\n",
    "# # Build the graph using trace_specs from above\n",
    "# fig = go.Figure(data=[\n",
    "#     go.Scatter(\n",
    "#         x=X[y==label].iloc[:, 0], y=X[y==label].iloc[:, 1],\n",
    "#         name=f'{split} data, Actual Class: {label}',\n",
    "#         mode='markers', marker_color=marker\n",
    "#     )\n",
    "#     for X, y, label, split, marker in trace_specs\n",
    "# ])\n",
    "\n",
    "# # Update marker size\n",
    "# fig.update_traces(marker_size=3, marker_line_width=0)\n",
    "\n",
    "# # Update axis range\n",
    "# fig.update_xaxes(range=[0, 14000])\n",
    "# fig.update_yaxes(range=[-50,50])\n",
    "\n",
    "# # Update chart title and legend placement\n",
    "# fig.update_layout(title_text=\"Decision Boundary\", \n",
    "#     legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1))\n",
    "\n",
    "# # Add contour graph\n",
    "# fig.add_trace(\n",
    "#     go.Contour(\n",
    "#         x=xrange,\n",
    "#         y=yrange,\n",
    "#         z=Z,\n",
    "#         showscale=True,\n",
    "#         colorscale='magma',\n",
    "#         opacity=1,\n",
    "#         name='Score',\n",
    "#         hoverinfo='skip'\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "skilled-wildlife",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X-axis = Traffic count\n",
    "# Y-axis = Temp\n",
    "# Range of color represents the probabilities of 'pm2.5>10' (class = 1)\n",
    "# Blue = pm2.5>10 (class 1)\n",
    "# Red = pm2.5<=10 (class 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "entitled-thought",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.20477056 0.33243767]\n",
      " [0.42795455 0.49846514]\n",
      " [0.38893409 0.45101393]\n",
      " ...\n",
      " [0.14690934 0.20873368]\n",
      " [0.43249694 0.46400384]\n",
      " [0.28177512 0.17774063]]\n"
     ]
    }
   ],
   "source": [
    "# print(model.predict_proba(X_new_test))\n",
    "print(X_new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "universal-galaxy",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
